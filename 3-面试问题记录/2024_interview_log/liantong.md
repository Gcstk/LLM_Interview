name:liantong

只写记得的
1. chatglm说说原理
2. gpt-sovits这种声音克隆的原理,算法
3. 微调的时候数据采集的注意点或者有什么建设性的操作吗?
4. 讲一下gpt和bert
还有一些不重要的,或者太难/偏的

pass了,人家想要的是数据清洗制作的,什么垃圾玩意儿,老子才不去



20240401回答:
1. glm
```text
ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构

为了方便下游开发者针对自己的应用场景定制模型，GLM同时实现了基于 P-Tuning v2 的高效参数微调方法

时下主流的预训练框架及其区别。主要有三种：

1、autoregressive自回归模型（AR模型）：代表作GPT。
本质上是一个left-to-right的语言模型。通常用于生成式任务，在长文本生成方面取得了巨大的成功，
比如自然语言生成（NLG）领域的任务：摘要、翻译或抽象问答。
当扩展到十亿级别参数时，表现出了少样本学习能力。
缺点是单向注意力机制，在NLU任务中，无法完全捕捉上下文的依赖关系。

2、autoencoding自编码模型（AE模型）：代表作BERT。
是通过某个降噪目标（比如MLM）训练的双向文本编码器。
编码器会产出适用于NLU任务的上下文表示，但无法直接用于文本生成。

3、encoder-decoder（Seq2seq模型）：代表作T5。采用双向注意力机制，
通常用于条件生成任务，比如文本摘要、机器翻译等。

GLM模型基于autoregressive blank infilling方法，结合了上述三种预训练模型的思想。
```
2. vits
```text
GPT-SOVITS是在SOVITS基础上做的：

SOVITS 作为语音转换框架，核心框架可以认为分为两部分:
1.生成器部分：主要基于VAE和FLOW模型（核心是VAE），用来做声音音色转换
    先验编码器：输入被转换的语音C，通过先验编码器，提取音色无关特征作为先验概率
    后验编码器：输入待模仿的目标语音A，形成后验条件概率分布
    解码器：将后验条件概率分布通过vocoder 的解码器形成声音B
    在训练时 B 应尽可能接近 A，在音色转换时，直接通过C 生成声音 B
2.鉴别器部分：主要基于GAN模型，用来对转换后声音进行判断

Vall-E 是基于 Encodec 来完成语音编码的生成。

GPT-SOVITS针对鉴别器相较于SOVITS5做了一些简化，主要的差异是在在生成模型处引入了残差量化层。
```




### 概念
1. seq2seq（sequence-to-sequence）代表着一种模型架构
```text
这种模型架构通常由两个主要组件组成：编码器（encoder）和解码器（decoder）。
"Seq" 是 "sequence" 的缩写，意味着序列。"2seq" 则是指从一个序列到另一个序列的转换过程。
```




### Reference
* [sovits](https://zhuanlan.zhihu.com/p/682397912)



