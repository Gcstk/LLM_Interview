## **1. Overview of Large Language Models (LLMs)**

Large Language Models are deep learning models trained on vast amounts of textual data to learn patterns, semantics, and syntactic structures of human languages. These models typically use the **transformer architecture**, introduced by Vaswani et al. in 2017, which relies heavily on self-attention mechanisms.

### Key Features of LLMs:
- **Self-Attention Mechanism**: Allows the model to weigh the importance of different words when interpreting context.
- **Scalability**: LLMs can contain hundreds of billions of parameters, enabling them to capture complex linguistic patterns.
- **Generalization Ability**: Pre-trained on diverse corpora, LLMs can perform a wide range of NLP tasks without task-specific training (zero-shot or few-shot learning).

---

## **2. The Role of Positional Encoding in Transformers**

Since the transformer model does not process sequences in a sequential manner like RNNs, it lacks inherent knowledge about token order. To address this, **positional encodings** are added to the input embeddings to provide the model with information about the relative or absolute positions of tokens.

Traditional positional encoding methods include:
- **Learnable Position Embeddings**: Learned during training, one embedding per position.
- **Sinusoidal Positional Encodings**: Fixed functions based on sine and cosine waves used in the original transformer paper.

While these methods work well for short sequences, they face limitations when dealing with long contexts or variable-length sequences.

---

## **3. Introduction to Rotary Position Embedding (RoPE)**

Rotary Position Embedding (RoPE) is a novel approach to incorporating positional information into attention mechanisms. It was first introduced in the paper *"SuRE: Rotary Position Embedding"* by Sun et al. and later popularized by models such as **YaRN** and **ChatGLM**.

### **Key Idea Behind RoPE**
RoPE rotates the query and key vectors in the attention mechanism according to their positions. This rotation introduces positional information directly into the computation of attention scores.

Mathematically, RoPE applies a rotation matrix to each position, transforming the queries and keys before computing dot products. The transformation preserves the relative distance between positions, allowing the model to better understand sequence structure.

---

## **4. Mathematical Formulation of RoPE**

Let’s denote:
- $ Q \in \mathbb{R}^{n \times d} $: Query matrix
- $ K \in \mathbb{R}^{n \times d} $: Key matrix
- $ V \in \mathbb{R}^{n \times d} $: Value matrix

For each position $ i $, the query vector $ q_i $ is rotated by an angle proportional to $ i $. Specifically, if we split the vector into pairs:

$$
q_i = [q_{i,0}, q_{i,1}, ..., q_{i,d/2-1}]
$$

Each pair $ (q_{i,2j}, q_{i,2j+1}) $ is rotated by a position-dependent angle $ \theta_j^m $, where $ m $ is the position index.

The rotation operation can be written as:

$$
\text{RoPE}(q_i, m) = q_i \circ R_m
$$

where $ R_m $ is a rotation matrix dependent on the position $ m $.

This formulation allows the attention score between two tokens to naturally incorporate their relative positions.

## 分类总结

垂域模型相关

1. 介绍一下这个项目,这个项目有多少人参加,你是什么角色?背景是什么?基于什么需求提出来要做的?整个项目难点是什么?
2. 微调的具体业务场景和需求是什么？为什么选择微调而不是RAG？
3. 微调结果如何评判？如何评价效果好坏？
4. 训练优化你到底做的哪方面的一些工作
5. 微调模型占用大小具体
6. 微调的数据处理细节，包括数据采集和挑战？
7. QLoRA与LoRA的区别、效果对比及选择依据？
8. 模型量化原理及具体量化方式？
9. Deepspeed微调细节，例如Zero阶段？
10. 微调模型占用大小及资源需求？
11. 当时选的这样参数量的一个原因? 为什么用这个模型来做微调和量化?
12. 微调的时候r=8,或者16有什么区别?你是怎么确定用哪个的?
13. 微调llm模型,过拟合的信号有哪些?采取怎么策略缓解
14. 微调框架怎么选的,有什么指标依据吗?
15. 模型微调的时候数据格式
16. 要有多少有效数据

---

知识库RAG相关
1. 如何rag检索很复杂的问题
2. 如何评价embedding的准确性,如何量化
3. 如何训练一个embedding的模型?
4. 本地知识库搭建细节介绍
5. 这个项目数据处理你具体做了哪些工作,怎么分工的?
6. rag好坏怎么评价?召回率,准确率
7. 团队的交付成果是以什么样的形态呈现
8. 团队你们是怎么样的分工配合呢
9. 知识库搭建的难点是什么?就最大的障碍是什么?
10. 构建知识库这一套的框架选型怎么选择的
11. 怎么做的数据采集
12. 文档怎么处理的,查询向量库用了什么哪些检索的方式呢?向量检索,bm25检索?
13. rag里面的知识怎么结构化的?
14. 文档里面表格,图片怎么处理?
15. 文档解析有什么心得没有?
16. rag中,如何提高准确率?
17. rerank和向量模型用的什么?

---

视觉模型微调相关
1. 介绍一下这个项目,这个项目有多少人参加,你是什么角色?背景是什么?基于什么需求提出来要做的?整个项目难点是什么?
2. 微调结果如何评判？如何评价效果好坏？
3. 微调模型占用大小具体
4. 如何量化不损失关心的方面的精度?
5. 微调时候使用量是多少,模型
6. 微调的时候r=8,或者16有什么区别?你是怎么确定用哪个的?
7. 过拟合的信号有哪些?怎么处理的?

---

通用模型相关问题
1. gradient_accumulation_steps 梯度累计步数解释一下
2. Qwen DeepSeek、LLaMA、GPT的架构对比
3. 注意力机制解释
4. 强化学习PPO 与 GRPO算法介绍,有哪些指标之类的?
5. 怎么加速推理,推理优化具体有什么心得,从模型架构和部署之后分别讲一下
6. 解释一下蒸馏,怎么做?
7. 多模态训练怎么做,多模态原理
8. 系统的学过那个机器学习的一些东西吗?有哪些?
9. 梯度更新算法解释
10. 如何减少过拟合,怎么判断
11. cv常用算法
12. svm,xgboost,lstm,cnn,rnn,k-means,random forest,knn,gnn,pca
13. f1,rmse/mse/mae r-squared,adjust r-squared,F statistics
14. kv cache通俗讲解
15. MOE架构介绍

---

Agent相关
1. 项目中agent怎么做的?
2. agent怎么实现,具体细节
3. agent智能体介绍一下你的做法,工作流介绍一下你用过的经验
4. 智能体这个你是怎么做的?
5. 内部智能客服agent怎么做的?

---

反洗钱项目相关
1. 说一说你反洗钱模型怎么做的?就是业务人员有什么经验什么是违规的交易/什么是洗钱交易?怎么把历史的业务经验转化为模型训练代码呢?
2. 这种模型的解释性你有研究吗?怎么做反洗钱模型的解释性?
3. 这个模型输入是单条交易线输入吗?有没有办法输入他一条线这种连续的感觉的那种交易
4. GNN怎么做呢?里面
5. 用户画像,这种标签怎么输入呢?
6. 反洗钱准确率多少,怎么修改,怎么优化,召回率怎么解决?
7. 风控的一些可疑非法交易这一块你能大概讲一下.
8. 你如何去判断它的一个效果?如果某一条数据不在真实数据里面怎么办?降低召回怎么解决?
9. 梯度提升和随机森林,SVM,PCA,K-means怎么看他们哪个指标得分?
10. 你根据这个得分怎么去后续的进行一些迭代?
11. 怎么让业务就是相信你给的数据可能是有效的?或者是说你能不能举个例子 有业务反馈这个东西需要迭代?然后你再怎么迭代的?

---

强化学习细节
DQN -> Policy-Based -> A2C/A3C -> PPO -> GRPO

---

## **5. Advantages of RoPE**

### **5.1 Relative Position Awareness**
Unlike absolute positional encodings, RoPE encodes **relative position information**, which is crucial for modeling dependencies in sequences.

### **5.2 Extrapolation to Longer Sequences**
RoPE can generalize to longer sequences than those seen during training, making it suitable for applications requiring long-context modeling.

### **5.3 Compatibility with Attention Computation**
RoPE integrates seamlessly into the attention mechanism without increasing computational complexity.

### **5.4 Simplicity and Efficiency**
It avoids the need for additional parameters (like learnable embeddings), reducing memory usage and improving efficiency.

---

## **6. Applications and Impact of RoPE**

RoPE has been adopted in several state-of-the-art LLMs, including:
- **ChatGLM series** by Zhipu AI
- **YaRN** (which extends RoPE for extrapolation)
- **Qwen** and other Alibaba Cloud models

These models benefit from RoPE's ability to scale to long sequences and maintain performance on downstream tasks such as question answering, summarization, and code generation.

---

## **7. Challenges and Future Directions**

Despite its advantages, RoPE is not without challenges:
- **Implementation Complexity**: Requires careful handling of rotations and vector dimensions.
- **Limited Interpretability**: Understanding exactly how positional information affects attention remains an open research area.

Future directions may include:
- Hybrid approaches combining RoPE with other positional encoding techniques.
- Improvements in extrapolation beyond training lengths.
- Application of RoPE to modalities beyond text, such as vision or speech.

---

## **Conclusion**

Rotary Position Embedding (RoPE) represents a significant advancement in the way large language models handle positional information. By integrating positional awareness directly into the attention mechanism through rotation operations, RoPE offers superior performance, especially for long sequences. As LLMs continue to evolve, innovations like RoPE will play a critical role in enhancing their capabilities and scalability.

---

## **References**

1. Vaswani, A., et al. (2017). *Attention Is All You Need*. NeurIPS.
2. Su, J., et al. (2021). *SuRE: Rotary Position Embedding*.
3. Du, Y., et al. (2022). *ChatGLM: A Series of Large Language Models from Zhipu AI*.
4. Press, O., et al. (2023). *Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation*.


---

通用问题:
1. 为什么没读研究生  ==> 已经有很多人或者说面试官自己就是研究生,所有想看看学习能力有没有?对于当前岗位他们觉得学历比较低.
   ```
    当时觉得程序员这个工作,本科学历是可以cover住的.随着阅历增加,发现还是有很多需要学习,所以在自己业余时间比如周末/下班也在补足,来使得自己满足岗位的需要
   ```
2. 为什么离职
   ```
   1. 自己有职业规划,希望去更大平台 2. 能力与薪资匹配
   ```
3. 职业规划是怎么样的?
   ```
   1. 打造个人ip,成为某一领域专家
   ```
4. 用几个词描述自己
    ```
    聪明,好学, 踏实/有感染力
    ```
5. 有其他offer吗?
    ```
    有一个offer,但是还在考虑中,他们对于当前AI岗位没有明确想法规划,只是觉得其他接入deepseek赋能提效,我们也要做
    ```
6. 你写的项目的话哪些就是落地了的
    ```
    all都是完成的了
    ```
7. 每个公司团队多少人,他们做什么的?其他人的话大概是什么样的角色
    ```
    1. 算法 大牛+me+同女
    2. 算法 领导+me+6人
    3. 大模型 me+算法+应届
    ```
8. 现在手上还有项目吗
    ```
    这几个月有2个比较大的项目
    通过AI做数据分析
    有个视觉模型的训练的项目,估计还需要2个月,
    ```
9.  你对我们公司了解多少
    ```
    有看过官网和了解过基础业务
    ```
10. 高考数学多少分呢?
    ```
    140
    ```
11. 你有什么想要问问我们的?
    ```
    有了AI后，希望能帮他们解决什么问题
    or
    公司当前在技术上最大的痛点问题是什么
    or
    到底缺什么?
    ```


---------

### 汇总

24:
1. 梯度更新算法
2. gpt和bert结构
3. 微调的时候数据采集的注意点或者有什么建设性的操作吗?
4. 如何优化减少多卡并行的损失率
5. 如何评价embedding的准确性,如何量化
6. 如何训练一个embedding的模型?
7. 如何rag检索很复杂的问题?
8. 查询向量库用了什么哪些检索的方式呢?
9. 为什么没读研究生
10. 本地知识库搭建细节
11. 对于AI的看法
12. 注意力解释,llama与gpt对比
13. 多模态训练怎么做

---

25:
1. qwen deepseek的架构
2. deepspeed微调时候的他的zero不同状态的细节原理
3. deepseek GRPO算法介绍
4. 怎么加速推理,从模型架构和部署之后分别讲一下
5. 项目中agent怎么做的?
6. 介绍一个你觉得印象最深的项目
7. 推理加速,推理加速,怎么极致使用显卡
8. 有哪些落地的项目比如说你举一两个
9. agent怎么实现,具体细节
10. gradient_accumulation_steps 梯度累计步数解释一下
11. r1这样的模型强化学习方面知识你了解多少,解释一下,有哪些指标之类的?
12. 分布式训练里面deepspeed使用介绍一下,zero1,zero2区别是什么?
13. agent智能体介绍一下你的做法,工作流介绍一下你用过的经验
14. 为什么离职
15. 高考数学多少分呢?
16. 微调的这个项目有多少人参加,你是什么角色?背景是什么?基于什么需求提出来要做的?
17. 文档里面表格,图片怎么处理
18. 总结一下你这个整个微调的方案 你认为你这个方案的优点是什么 你这块如果说让你重新做的话 你会怎么做?
19. deepseek的框架与llama有什么区别?
20. 怎么做模型输出准确率优化?
21. 团队成员双方出现意见分歧的时候怎么办?
22. 请简要解释为什么transformer中有mha
23. 微调llm模型,过拟合的信号有哪些?采取怎么策略缓解
24. 怎么解决llm幻觉问题?dpo和rlhf怎么改善幻觉?
25. 微调有没有采用rlhf?怎么做的?
26. 讲一下模型微调项目细节,是解决什么场景下这个问题?
27. 和rag有什么区别?为什么不用rag?
28. 微调结果怎么去评判他回答的好或者不好?
29. 在最后这家公司你觉得是你理想的工作状态吗?
30. 说一说你反洗钱模型怎么做的?就是业务人员有什么经验什么是违规的交易/什么是洗钱交易?怎么把历史的业务经验转化为模型训练代码呢?
31. 这种模型的解释性你有研究吗?怎么做反洗钱模型的解释性?
32. 这个模型输入是单条交易线输入吗?有没有办法输入他一条线这种连续的感觉的那种交易
33. GNN怎么做呢?里面
34. 用户画像,这种标签怎么输入呢?
35. 反洗钱准确率多少,怎么修改,怎么优化,召回率怎么解决?
36. 你对这个收入的诉求大概是什么样子?
37. 你现在是出来找工作原因是什么?
38. 你挑一个做的最好的一个项目讲一下
39. 风控的一些可疑非法交易这一块你能大概讲一下.
40. 你如何去判断它的一个效果?如果某一条数据不在真实数据里面怎么办?降低召回怎么解决?
41. 梯度提升和随机森林,SVM,PCA,K-means怎么看他们哪个指标得分?
42. 你根据这个得分怎么去后续的进行一些迭代?
43. 怎么让业务就是相信你给的数据可能是有效的?或者是说你能不能举个例子 有业务反馈这个东西需要迭代?然后你再怎么迭代的?
44. 系统的学过那个机器学习的一些东西吗?有哪些?
45. 全参数微调,lora微调有什么区别吗,具体冻结了哪些层的参数
46. deepspeed的不同阶段
47. 解释一下量化的awq,gguf等他们的差别
48. 解释一下蒸馏,怎么做?
49. 智能体这个你是怎么做的?
50. 内部智能客服agent怎么做的?
51. 企业垂直领域模型微调针对哪个垂直领域?具体到场景. 用的什么框架? 
52. 上面问题数据怎么构建的?
53. 对效果评估打分怎么做的?有没有一套成熟的方案?
54. 多卡并行里面 accelerate讲一下注意的点 deepspeed说一下它的zero1,zero2的区别
