20250513面试记录

1. 你做过rag或者微调吗?
2. 什么时候用微调,什么时候用rag,你是怎么去构想的
3. lora微调的时候r=8,或者16有什么区别?你是怎么确定用哪个的?
```
现在反思一下其实不是一个参数解决的,还有一个lora_alpha(一般是2*r,4*r),毕竟是 lora_alpha/r来计算的,r当然还是单独也重要,毕竟矩阵分解的那个小边,变大其实会使得你的lora模型变大,效果好一点,但是本身就是lora了,你要是很大那我不如全量微调了
```
4. gradient_accumulation_steps梯度累计步数解释一下
5. rag里面的知识怎么结构化的?
6. pdf,word,ppt这样的文件处理方式
7. r1这样的模型强化学习方面知识你了解多少,解释一下,有哪些指标之类的?
8. 分布式训练里面deepspeed使用介绍一下,zero1,zero2区别是什么?
9. agent智能体介绍一下你的做法,工作流介绍一下你用过的经验
10. 还给了一个算法题
```
珂珂喜欢吃香蕉。这里有 n 堆香蕉，第 i 堆中有 piles[i] 根香蕉。警卫已经离开了，将在 h 小时后回来。
珂珂可以决定她吃香蕉的速度 k （单位：根/小时）。每个小时，她将会选择一堆香蕉，从中吃掉 k 根。
如果这堆香蕉少于 k 根，她将吃掉这堆的所有香蕉，然后这一小时内不会再吃更多的香蕉。
珂珂喜欢慢慢吃，但仍然想在警卫回来前吃掉所有的香蕉。
返回她可以在 h 小时内吃掉所有香蕉的最小速度 k（k 为整数）。

示例 1：
输入：piles = [3,6,7,11], h = 8
输出：4

示例 2：
输入：piles = [30,11,23,4,20], h = 5
输出：30

示例 3：
输入：piles = [30,11,23,4,20], h = 6
输出：23

提示：
1 <= piles.length <= 104
piles.length <= h <= 109
1 <= piles[i] <= 109
```
