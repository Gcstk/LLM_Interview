20250527面试记录

外企 线下面试,英文ppt+英文自我介绍

一共四个人面试,挺重视的,就是园区似乎有点紧啊,这工位..

面试官对技术不太了解,其实,但是我觉得他们应该见过很多人,只需要看谈吐就知道这个人能不能胜任工作了
所以,还是需要有敬畏之心,别忽悠别人.

球球了,让老子过吧,我觉得外企挺好的

---

1. 你对这些职位对我们公司都了解的多吗
2. 英语有问题吗?讲一下英语ppt用3-5分钟
3. 你是学数学的,你高考考了多少分?数学呢?
4. 为什么离职...
   --------省略我的个人信息问题

---

1. 微调的这个项目有多少人参加,你是什么角色?背景是什么?基于什么需求提出来要做的?
2. 文档解析有什么心得没有?
3. 让别人提供的文档如何去重?或者下面4个问题怎么解决的?

    ```
    多个师傅经验相似：不同师傅可能回答的是同一种故障或流程，只是表达方式略有不同。
    问题描述角度相同：虽然内容不同，但用户提问的角度太接近，导致模型学不到更多泛化能力。
    缺乏统一标准：没有统一模板或指引，导致数据采集随意。
    数据质量参差不齐：有些师傅写得多，有些写得少，有些写得好，有些写得不好。
    ```

    ```
    先建立一个初步的知识结构，比如：
    设备分类 → 故障类型 → 解决方法 → 常见问题

    制定统一的问答格式模板
    按照知识结构分派任务给不同师傅

    自动去重（基于语义相似度）
    人工审核合并

    微调时候可以加入负样本（错误回答）提升鲁棒性(建议负样本不超过总样本的 20%)
    自动构造-用模型生成错误回答（对抗样本）
    人工构造-可由专家编写明显错误的回答

    总结:结构化采集 + 相似度检测 + 人工审核 + 激励多样化(提供积分、小礼品)
    ```
4. 文档里面表格,图片怎么处理?
5. 总结一下你这个整个微调的方案 你认为你这个方案的优点是什么 你这块如果说让你重新做的话 你会怎么做?
6. 模型lora的原理以及公式
7. deepseek的框架与llama有什么区别?
8. T5模型微调有没有什么经验?怎么做的
9. 怎么做模型输出准确率优化?
10. 修改主流大模型你会改吗?
11. 双方出现意见分歧的时候怎么办?
12. lstm训练模型时候有哪些指标?
13. 可以训练视觉模型来针对空调做问题检测吗?




---



#### 自动去重（基于语义相似度）怎么做？
我们要对所有“问题”部分进行语义向量化，然后计算两两之间的相似度（如余弦相似度），如果超过某个阈值（比如0.85），就认为是重复或高度相似的问题。

```python
from sentence_transformers import SentenceTransformer, util
import torch
import pandas as pd

# 假设你有一个 DataFrame，列名为 'question'
df = pd.DataFrame({
    'question': [
        "设备启动后没有反应怎么办？",
        "机器开不了机怎么处理？",
        "如何更换滤芯？",
        "滤芯怎么换？",
        "电机过热了怎么解决？"
    ]
})

# 加载预训练模型
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# 获取所有问题的嵌入向量
sentences = df['question'].tolist()
embeddings = model.encode(sentences, convert_to_tensor=True)

# 计算余弦相似度矩阵
cos_sim = util.cos_sim(embeddings, embeddings)

# 设置阈值
threshold = 0.85

# 找出相似度大于阈值的句子对
similar_pairs = []
for i in range(len(sentences)):
    for j in range(i + 1, len(sentences)):
        if cos_sim[i][j] > threshold:
            similar_pairs.append((i, j, cos_sim[i][j].item()))

print("找到的相似问题对：")
for i, j, sim in similar_pairs:
    print(f"问题 {i}: '{sentences[i]}'")
    print(f"问题 {j}: '{sentences[j]}'")
    print(f"相似度: {sim:.4f}\n")

# 可以根据结果手动或自动去重
# 例如保留第一个，删除第二个
to_remove = set(j for i, j, _ in similar_pairs)
df_filtered = df.drop(index=to_remove).reset_index(drop=True)

print("去重后的问答对：")
print(df_filtered)
```


#### PEFT微调LLM时可以加入负样本吗？怎么做？

- 正样本
```json
{
  "input": "设备无法启动，可能是什么原因？",
  "output": "检查电源是否接通，保险丝是否烧毁，控制面板是否有报警信息。"
}
```
- 负样本
```json
{
  "input": "设备无法启动，可能是什么原因？",
  "output": "可能是润滑不足导致轴承磨损。"  // 明显错误的回答
}
{
  "input": "设备无法启动，可能是什么原因？",
  "output": "[ERROR] 这个回答是故意构造的错误样本，请忽略。"
}
```

```python
from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model
import datasets
import pandas as pd

# 加载 tokenizer 和 base model
model_name = "meta-llama/Llama-3-8b"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# PEFT 配置
peft_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, peft_config)

# 构建训练数据（含正样本 + 负样本）
train_data = [
    # 正样本
    {"input": "设备无法启动，可能是什么原因？", "output": "请检查电源、保险丝、急停按钮等"},
    {"input": "如何更换滤芯？", "output": "关闭阀门 → 卸下旧滤芯 → 安装新滤芯"},

    # 负样本（明显错误的回答）
    {"input": "设备无法启动，可能是什么原因？", "output": "可能是润滑不足导致轴承磨损（但这个问题与启动无关）"},
    {"input": "如何更换滤芯？", "output": "直接用锤子砸开过滤器即可（危险操作，不推荐）"}
]

# 将数据转换为 Dataset 格式
dataset = datasets.Dataset.from_pandas(pd.DataFrame(train_data))

# 数据处理函数（tokenize input 和 output）
def tokenize_function(examples):
    tokenized_inputs = tokenizer(
        examples["input"], 
        text_target=examples["output"],  # 这里包含了正样本和负样本的输出
        padding="max_length", 
        truncation=True, 
        max_length=512
    )
    return tokenized_inputs

# 对整个数据集进行 tokenization
tokenized_datasets = dataset.map(tokenize_function, batched=True)

# 数据整理器（用于动态 padding）
data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)

# 设置训练参数
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=2,
    num_train_epochs=3,
    logging_dir="./logs",
    save_steps=100,
    logging_steps=10,
    learning_rate=1e-4,
    report_to="none"  # 可选 wandb 或 tensorboard
)

# 创建 Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets,
    data_collator=data_collator,
)

# 开始训练
trainer.train()
```

- 关键点说明（负样本体现在哪？）

| 位置 | 说明 |
|------|------|
| `train_data` 构造部分 | 手动添加了负样本，这些是错误的、不相关或误导性的回答 |
| `text_target=examples["output"]` | 训练目标是 output 字段，它既可以是正确答案，也可以是负样本 |
| `tokenized_datasets.map(...)` | 整个数据集包含正样本和负样本一起被编码进模型输入中 |

给负样本加权重（损失函数控制）

对负样本给予不同的 loss 权重，可以在自定义 Trainer 中实现

```python
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits

        # 假设在 inputs 中有一个字段 is_negative（1 表示负样本）
        weights = torch.where(inputs["is_negative"] == 1, 0.5, 1.0)  # 给负样本降低权重

        loss_fct = torch.nn.CrossEntropyLoss(reduction='none')
        shift_logits = logits[..., :-1, :].contiguous()
        shift_labels = labels[..., 1:].contiguous()

        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
        weighted_loss = (loss * weights.view(-1)).mean()

        return (weighted_loss, outputs) if return_outputs else weighted_loss
```