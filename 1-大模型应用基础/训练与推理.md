1. 大模型有推理能力吗?

```text
是的，大语言模型具备推理能力
推理是指在训练阶段之后，使用已经训练好的模型对新的输入数据进行预测、生成或分类等任务。大语言模型可以通过输入一段文本或问题，然后生成相应的回答或补全文本。
```

2. SFT（有监督微调）的数据集格式？

```text
SFT（Supervised Fine-Tuning）
1. 输入数据：输入数据是一个文本序列，通常是一个句子或者一个段落。每个样本可以是一个字符串或者是一个tokenized的文本序列。
2. 标签数据：标签数据是与输入数据对应的标签或类别。标签可以是单个类别，也可以是多个类别的集合。对于多分类任务，通常使用one-hot编码或整数编码来表示标签。
3. 数据集划分：数据集通常需要划分为训练集、验证集和测试集。训练集用于模型的训练，验证集用于调整模型的超参数和监控模型的性能，测试集用于评估模型的最终性能。
4. 数据集格式：数据集可以以文本文件（如CSV、JSON等）或数据库的形式存储。每个样本包含输入数据和对应的标签。可以使用表格形式存储数据，每一列代表一个特征或标签。
下面是一个示例数据集的格式：

Input,Label
"This is a sentence.",1
"Another sentence.",0
在这个示例中，输入数据是一个句子，标签是一个二分类的标签（1代表正例，0代表负例）。
每一行代表一个样本，第一列是输入数据，第二列是对应的标签。
需要注意的是，具体的数据集格式可能会因任务类型、数据来源和使用的深度学习框架而有所不同。
因此，在进行SFT训练时，建议根据具体任务和框架的要求来定义和处理数据集格式。
```

3. RM（Reward Model，奖励模型）的数据格式

```text
输入数据是一个句子，奖励数据是一个实数值，表示对输入数据的评价。每一行代表一个样本，第一列是输入数据，第二列是对应的奖励数据
Input,Reward
"This is a sentence.",0.8
"Another sentence.",0.2
```

4. 微调需要多少条数据？

```text
小规模模型：对于小规模的语言模型，通常需要较少的数据量进行微调。一般来说，几千到几万条数据可能已经足够
大规模模型：对于大规模的语言模型，通常需要更多的数据量进行微调。数十万到数百万条数据可能是常见的范围
```

5. 为什么大模型推理时显存涨的那么多还一直占着？

```text
模型参数占用显存：在推理过程中，模型参数会占用相当大的显存空间。
输入数据占用显存：进行推理时，需要将输入数据加载到显存中
中间计算结果占用显存：在推理过程中，模型会进行一系列的计算操作，生成中间结果。
```

6. 推理速度上，int8和fp16比起来怎么样？INT4/INT8是什么意思?

```text
使用INT8（8位整数量化）和FP16（半精度浮点数）相对于FP32（单精度浮点数）可以带来一定的加速效果
具体来说，INT8在相同的内存空间下可以存储更多的数据，FP16在相对较小的数据范围内进行计算
int8 表示整数的数据类型，只有8位（1字节）来表示一个数字,精度较低
fp16 表示浮点数的数据类型，使用16位（2字节）来表示一个数字
```

7. 大模型生成时的参数怎么设置？

```text
模型选择=>模型加载=>推理算法=>温度参数=>推理长度=>其他参数
```

8. 如何让大模型输出合规化

```text
数据清理和预处理=>审查和验证模型=>引入合规性约束=>监控和更新模型=>合规培训和教育
```

9.过拟合解决办法

```text
1.训练数据比较小,或者样本里面的噪声数据干扰过大，导致模型过分记住了噪声特征
2.残差连接(模仿transformer里面的)
```

